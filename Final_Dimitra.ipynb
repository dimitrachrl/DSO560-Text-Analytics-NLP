{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ead7e32e7f8945f4864e22b85051414e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bbba5ad3ded34df696644388b9ecd713",
              "IPY_MODEL_45c17762adb0435aa6f2b3859bc32175",
              "IPY_MODEL_e171698820ca4461a5f408fbf615de3c"
            ],
            "layout": "IPY_MODEL_05b8ddb15c54405f9801bab3e46cc31f"
          }
        },
        "bbba5ad3ded34df696644388b9ecd713": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0e2eb72141424ed6bd9548afd3fa2c5c",
            "placeholder": "​",
            "style": "IPY_MODEL_17dce98930a24dd48268e6d62f0aa39f",
            "value": "Downloading: 100%"
          }
        },
        "45c17762adb0435aa6f2b3859bc32175": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9264cbe4f3f34fc9bd1e48a8d87f7ce8",
            "max": 714314041,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a7843621b8204dbe86749218a24e9bd7",
            "value": 714314041
          }
        },
        "e171698820ca4461a5f408fbf615de3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e3b32a4222244c9cab0193e8fe358628",
            "placeholder": "​",
            "style": "IPY_MODEL_4931002ba21b4261871335435deea482",
            "value": " 714M/714M [00:34&lt;00:00, 24.5MB/s]"
          }
        },
        "05b8ddb15c54405f9801bab3e46cc31f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0e2eb72141424ed6bd9548afd3fa2c5c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "17dce98930a24dd48268e6d62f0aa39f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9264cbe4f3f34fc9bd1e48a8d87f7ce8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a7843621b8204dbe86749218a24e9bd7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e3b32a4222244c9cab0193e8fe358628": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4931002ba21b4261871335435deea482": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Problem #1"
      ],
      "metadata": {
        "id": "Htai7Ila7PSl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "950h4XGZ6_pA"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "np.set_printoptions(precision=3, suppress = True)\n",
        "\n",
        "d_model = 8\n",
        "max_positions = 4\n",
        "\n",
        "position_enc = np.zeros((max_positions,d_model))\n",
        "\n",
        "for pos in range (max_positions):\n",
        "  for i in range (d_model):\n",
        "    position_enc[pos,i] = np.array(pos/np.power(10000, 2*i / d_model))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "position_enc_sin_cosine = np.zeros((max_positions, d_model))\n",
        "\n",
        "position_enc_sin_cosine[1:, 0::2] = np.sin(position_enc[1:, 0::2])\n",
        "position_enc_sin_cosine[1:, 1::2] = np.cos(position_enc[1:, 1::2])\n",
        "\n",
        "print(position_enc_sin_cosine)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w9wUUv3b_Meb",
        "outputId": "5d6772ba-1aaa-4cdd-a8bb-ddd44e71671a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.    0.    0.    0.    0.    0.    0.    0.   ]\n",
            " [0.841 0.995 0.01  1.    0.    1.    0.    1.   ]\n",
            " [0.909 0.98  0.02  1.    0.    1.    0.    1.   ]\n",
            " [0.141 0.955 0.03  1.    0.    1.    0.    1.   ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.spatial.distance import cosine\n",
        "pos1 = position_enc_sin_cosine[1]\n",
        "pos3 = position_enc_sin_cosine[3]\n",
        "\n",
        "print(f'Cosine distance with positional embeddings') \n",
        "print('p1->p3')\n",
        "print(cosine(pos1, pos3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ey6wFNMfAdWP",
        "outputId": "e1d85aef-0cab-4535-bd36-54529dfee354"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cosine distance with positional embeddings\n",
            "p1->p3\n",
            "0.053330553292434746\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Problem #2"
      ],
      "metadata": {
        "id": "pDLzybwhAqt1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy import special"
      ],
      "metadata": {
        "id": "jV30h6eBDc31"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_1 = np.array([1, 0, 1, 0])\n",
        "word_2 = np.array([0, 2, 2, 2])\n",
        "word_3 = np.array([1, 1, 1, 1])\n",
        "\n",
        "W_Q = np.array([[0, 0, 1],\n",
        "[1, 1, 0],\n",
        "[0, 1, 0],\n",
        "[1, 1, 0]])\n",
        "\n",
        "W_K = np.array([[1, 0, 1],\n",
        "[1, 0, 0],\n",
        "[0, 1, 0],\n",
        "[1, 0, 1]])\n",
        "\n",
        "W_V = np.array([[1, 0, 1],\n",
        "[1, 1, 0],\n",
        "[0, 1, 1],\n",
        "[0, 0, 1]])"
      ],
      "metadata": {
        "id": "f35nN4fBAsve"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Q = np.dot( np.array((word_1, word_2, word_3)), W_Q)\n",
        "K = np.dot(np.array((word_1, word_2, word_3)), W_K)\n",
        "V = np.dot(np.array((word_1, word_2, word_3)), W_V)"
      ],
      "metadata": {
        "id": "jYz5-Yy8CqHP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "attn_scores = np.dot(Q, K.transpose())"
      ],
      "metadata": {
        "id": "nEZZUOOcD5bI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "normalized_attn_scores = attn_scores / K.shape[1] ** 0.5"
      ],
      "metadata": {
        "id": "DbclMHa7DNzd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "attn_scores_softmax = special.softmax(normalized_attn_scores, axis=1)"
      ],
      "metadata": {
        "id": "suqkGZFgEXtH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "attn_output = np.dot(attn_scores_softmax, V)"
      ],
      "metadata": {
        "id": "ruHfL4_pEfWU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Attention Vector')\n",
        "print(attn_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rk2s5n_GEi8s",
        "outputId": "bb62e240-b095-4c6a-8ab8-81ca383ce4a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Attention Vector\n",
            "[[1.832 2.898 3.365]\n",
            " [2.    3.994 3.997]\n",
            " [1.997 3.886 3.941]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Problem #3"
      ],
      "metadata": {
        "id": "wndb-noUFOIZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install transformers\n",
        "! pip install git+https://github.com/huggingface/transformers.git"
      ],
      "metadata": {
        "id": "bfDoxZCFFRCr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline"
      ],
      "metadata": {
        "id": "zr0rKYC6Fnhi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Problem 3.1\n",
        "classifier = pipeline('sentiment-analysis')"
      ],
      "metadata": {
        "id": "Xo7VPHlKF1sK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier('I like NLP course.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-mcIZCIrGr_H",
        "outputId": "577cf415-02fe-4c14-e35e-52df9138c01f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'label': 'POSITIVE', 'score': 0.9993118047714233}]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classifier('I hate when my computer crasehs.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YBg_FaWZGWW4",
        "outputId": "1f325f75-6d0f-4790-d1a8-4a7c82c3dbdd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'label': 'NEGATIVE', 'score': 0.9993535876274109}]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Problem 3.2\n",
        "classifier = pipeline('zero-shot-classification')"
      ],
      "metadata": {
        "id": "DH0e23hJGYg2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier('Los Angeles Clipper is a good basketball team', candidate_labels=['sports', 'politics', 'education'],)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uZTY1HhjGvG_",
        "outputId": "db482acb-2151-4d1b-96f4-01179254312a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'sequence': 'Los Angeles Clipper is a good basketball team',\n",
              " 'labels': ['sports', 'education', 'politics'],\n",
              " 'scores': [0.9973015189170837, 0.0016447460511699319, 0.0010537264170125127]}"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Problem 3.3\n",
        "gen = pipeline('text-generation')"
      ],
      "metadata": {
        "id": "MiIP5GpCHGqS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gen('In this month, the stock market will')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zyPnb9WKHIQg",
        "outputId": "10f6a16f-ee93-4265-c5c1-95c82ee12df3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/transformers/generation/utils.py:1201: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation)\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/generation/utils.py:1288: UserWarning: Using `max_length`'s default (50) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'generated_text': \"In this month, the stock market will be gripped by high volatility, not yet fully recovered. Even if it recovers, it won't be enough.\"}]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Problem 3.4\n",
        "gen = pipeline('fill-mask')"
      ],
      "metadata": {
        "id": "Pb7HOLYBHVKJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gen('Math course will teach you about <mask> topics.', top_k=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q1hUI2HaHct3",
        "outputId": "6fdece67-1683-4299-d978-426966a7fcf2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'score': 0.11557416617870331,\n",
              "  'token': 30412,\n",
              "  'token_str': ' mathematical',\n",
              "  'sequence': 'Math course will teach you about mathematical topics.'},\n",
              " {'score': 0.0893840342760086,\n",
              "  'token': 10638,\n",
              "  'token_str': ' math',\n",
              "  'sequence': 'Math course will teach you about math topics.'}]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Problem 3.5\n",
        "gen = pipeline('ner',grouped_entities=True)"
      ],
      "metadata": {
        "id": "z-0YN4qOHh-z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gen('Tim Cook is the CEO of Apple located in San Jose.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TpyUnFDeHoZ6",
        "outputId": "e0ea589b-c068-4662-eed3-b5ade0193b3b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'entity_group': 'PER',\n",
              "  'score': 0.9997417,\n",
              "  'word': 'Tim Cook',\n",
              "  'start': 0,\n",
              "  'end': 8},\n",
              " {'entity_group': 'ORG',\n",
              "  'score': 0.99871206,\n",
              "  'word': 'Apple',\n",
              "  'start': 23,\n",
              "  'end': 28},\n",
              " {'entity_group': 'LOC',\n",
              "  'score': 0.9983774,\n",
              "  'word': 'San Jose',\n",
              "  'start': 40,\n",
              "  'end': 48}]"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Problem 3.6\n",
        "gen = pipeline('question-answering')"
      ],
      "metadata": {
        "id": "HV1TsAOgHwRz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gen(question='In which state Los Angeles located', context='Los Angeles is in California')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iOyyIcMuH2ZA",
        "outputId": "ad8359de-007d-474b-80a8-35058ea5473f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'score': 0.9838225245475769, 'start': 18, 'end': 28, 'answer': 'California'}"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Problem 3.7\n",
        "gen = pipeline('summarization')"
      ],
      "metadata": {
        "id": "A0GYv--lH3SB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gen(''' Australia was celebrated for its initial response to the Covid-19 pandemic, and for getting its economy more or less back on track long ago. But with\n",
        "that security has come complacency, particularly in the federal government,\n",
        "which failed to secure enough vaccine doses to prevent the regular \"circuit breaker\" lockdowns that come every time a handful of cases emerge, or even\n",
        "the longer restrictions that Sydney is experiencing now. Australia's borders, controlled by strict quarantine measures, have been all but shut for more than a year. Now Australians, who basked in their early successes, are wondering how much longer this can go on. ''')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YpcTomqyH6HC",
        "outputId": "75556e99-65e2-4226-86db-74f0ce058342"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 142, but you input_length is only 134. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=67)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'summary_text': \" Australia was celebrated for its initial response to the Covid-19 pandemic . But with that security has come complacency, particularly in the federal government . Australia's borders, controlled by strict quarantine measures, have been all but shut for more than a year . Now Australians are wondering how much longer this can go on .\"}]"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Problem #4"
      ],
      "metadata": {
        "id": "SxBYQTaCIB1y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install flair"
      ],
      "metadata": {
        "id": "5a423ajAIA-6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np \n",
        "from flair.embeddings import WordEmbeddings\n",
        "from flair.embeddings import TransformerWordEmbeddings\n",
        "from flair.data import Sentence\n",
        "from scipy.spatial import distance"
      ],
      "metadata": {
        "id": "IBpHShqfIUQw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Glove \n",
        "glove_embedding = WordEmbeddings('glove')"
      ],
      "metadata": {
        "id": "33Xu2hhcIi9W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_1 = Sentence('I went to a bank to deposit money.')\n",
        "sentence_2 = Sentence('I sat near a bank of a river.')"
      ],
      "metadata": {
        "id": "xL-WJ2iEInzb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "glove_embedding.embed(sentence_1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YKiehJuzIxcp",
        "outputId": "4db99f2b-91c4-4d89-adda-7d54b278a393"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Sentence[9]: \"I went to a bank to deposit money.\"]"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "glove_embedding.embed(sentence_2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aPHQTCIxJaPD",
        "outputId": "277b63f0-bd72-4253-c9b1-07d9fddeb842"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Sentence[9]: \"I sat near a bank of a river.\"]"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "glove_dst = distance.euclidean(np.array(sentence_1[4].embedding), np.array(sentence_2[4].embedding))\n",
        "print(\"Glove embedding: Euclidian distance between the embeddings for the word ‘bank’ used in 2 sentences = {}\".format(glove_dst))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gp8m3X29JgGA",
        "outputId": "cf0a2a0f-7802-45fc-f809-d6fe03319a7f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Glove embedding: Euclidian distance between the embeddings for the word ‘bank’ used in 2 sentences = 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Bert\n",
        "from flair.embeddings import TransformerWordEmbeddings\n",
        "from transformers.models.bert.modeling_bert import BertModel,BertForMaskedLM"
      ],
      "metadata": {
        "id": "Tb23SqvKJtX4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bert_embedding = TransformerWordEmbeddings('bert-base-multilingual-cased')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "ead7e32e7f8945f4864e22b85051414e",
            "bbba5ad3ded34df696644388b9ecd713",
            "45c17762adb0435aa6f2b3859bc32175",
            "e171698820ca4461a5f408fbf615de3c",
            "05b8ddb15c54405f9801bab3e46cc31f",
            "0e2eb72141424ed6bd9548afd3fa2c5c",
            "17dce98930a24dd48268e6d62f0aa39f",
            "9264cbe4f3f34fc9bd1e48a8d87f7ce8",
            "a7843621b8204dbe86749218a24e9bd7",
            "e3b32a4222244c9cab0193e8fe358628",
            "4931002ba21b4261871335435deea482"
          ]
        },
        "id": "ItjiSEs0KYix",
        "outputId": "77679947-cdcc-440d-efd5-3ef3830737e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/714M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ead7e32e7f8945f4864e22b85051414e"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bert_embedding.embed(sentence_1)\n",
        "bert_embedding.embed(sentence_2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xVjde8azZbC4",
        "outputId": "662f09bc-6366-41d8-ad1c-7a7062b026f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Sentence[9]: \"I sat near a bank of a river.\"]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bert_dst = distance.euclidean(np.array(sentence_1[4].embedding), np.array(sentence_2[4].embedding))"
      ],
      "metadata": {
        "id": "0RHv2n9faAHT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"BERT embeddings: Euclidian distance between the embeddings for the word ‘bank’ used in 2 sentences ≠ {}\".format(bert_dst))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WqpcTuEQaKwW",
        "outputId": "0621e7d0-2afc-4e47-fd87-76564a7f4341"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BERT embeddings: Euclidian distance between the embeddings for the word ‘bank’ used in 2 sentences ≠ 14.108161926269531\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Problem #5"
      ],
      "metadata": {
        "id": "-TrgVHFALyY8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In her paper and talk, Professor Emily M. Bender raises important concerns about the potential dangers associated with the increasing size and power of language models (LMs) such as GPT-3. She raises the question as to “How big is too big?” and voices her concerns regarding the risks associated with LMs. Additionally, she provides recommendations to weigh the costs associated with these models and high lites the need for ethical guidelines and oversight in their development and use.\n",
        "\n",
        "According to her, the development of increasingly large LMsin natural language processing (NLP) raises concerns about their potential risks, particularly in terms of environmental impact, biased training data, limitations of LMs in natural language understanding (NLU), and the potential for harm caused by reproducing harmful ideologies. As discussed in the paper, the significant environmental costs associated with training and using large language models like GPT-3. She notes that training these models requires massive amounts of energy, which can contribute to climate change and other environmental issues.\n",
        "\n",
        "Another thing that Bender highlights is the potential for language models to amplify existing biases in the data due to the vast amount of data available. Language models are designed to predict the likelihood of a sequence of words given previous words, and they achieve this by analyzing large amounts of text data. However, this process can reinforce and amplify existing biases in the data, leading to harmful stereotypes and discriminatory language. After all, size doesn’t guarantee diversity. Bender suggests that a better approach would be instead of accepting large amounts of web text as ‘representative’ of all humanity  to actively seek to include communities underrepresented on the Internet. \n",
        "\n",
        "She also discusses two challenges associated with large language models (LMs): static data/changing social views and encoding bias. The first challenge relates to how social movements produce new norms, language, and ways of communicating that are not captured by LMs, which can result in older, less inclusive understandings being reinforced. Encoding bias is the second challenge, where LMs exhibit various kinds of bias, including stereotypical associations and negative sentiment towards specific groups. The article notes that automated systems for measuring biases may not be reliable, and that auditing an LM for biases requires an understanding of what social categories might be salient. Finally, the article notes that building systems that verify the safety of LMs requires engaging with the systems of power that lead to harmful outcomes, which is necessarily political.\n",
        "\n",
        "Bender highlights the danger of LMs picking up biases from their training data, which may include harmful stereotypes and negative associations. When LMs produce text, there is a risk of propagating and amplifying these biases, leading to discrimination and harm. Language models can be used to generate text that is indistinguishable from human-written text, which could be used to spread misinformation or hate speech. Bender notes that ethical guidelines and oversight are needed to ensure their ethical and responsible deployment.\n",
        "\n",
        "Overall, Bender's paper and talk highlight the need for ethical considerations and oversight in the development and use of language models to mitigate the risks associated with their development. She suggest that researchers should prioritize the development of a technological ecosystem whose benefits are evenly distributed or accrue to those historically marginalized. To achieve this, researchers must consider the financial and environmental costs of LM development, incorporate energy and compute efficiency, and carefully curate data. They must also adopt frameworks to describe the uses for which their models are suited and benchmark evaluations for a variety of conditions. She also recommends a realignment of research goals and the adoption of guided evaluation exercises, value-sensitive design, and conceptual investigations of values and harms. Ultimately,  the development of language technology must be done with forethought and care.\n",
        "\n"
      ],
      "metadata": {
        "id": "ZoL2vBHqcAK_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Problem #6"
      ],
      "metadata": {
        "id": "eO9EgFAyL5td"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "df = pd.read_csv('worldfloras.csv')\n",
        "df['Country'] = df['Country'].fillna('')"
      ],
      "metadata": {
        "id": "V0Hrey2kL7X1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#1\n",
        "countries = df[df['Country'].str.contains(r'^.z')]['Country'].tolist()\n",
        "print(countries)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EEKeMCJxNZap",
        "outputId": "68ffacaa-041f-4e3a-dfd7-02f364d04122"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Czechoslovakia']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#2\n",
        "countries = df[df['Country'].str.contains(r'^....h')]['Country'].tolist()\n",
        "print(countries)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1SIXfR5MN-gN",
        "outputId": "d6de6f76-8467-415e-b13a-476ab4518cf3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Czechoslovakia', 'Liechtenstein', 'Seychelles', 'South Africa']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#3\n",
        "countries = df[df['Country'].str.contains(r'^.......l')]['Country'].tolist()\n",
        "print(countries)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KAb5-VLvOMn0",
        "outputId": "3fe9c736-6922-4397-e8d7-8eb203cfae1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Czechoslovakia', 'Guatemala', 'New Zealand', 'Portugal', 'Seychelles', 'Switzerland', 'Venezuela']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#4\n",
        "countries = df[df['Country'].str.contains(r'^...........k')]['Country'].tolist()\n",
        "print(countries)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mWhcXO2eOOlY",
        "outputId": "0c7d7e76-8f4e-4532-9986-279672e6f68a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Czechoslovakia']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Problem #7"
      ],
      "metadata": {
        "id": "sCEJXgHlOb7I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer \n",
        "from sklearn.feature_extraction.text import TfidfTransformer \n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('brown')\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.corpus import brown\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize \n",
        "from operator import itemgetter\n",
        "stop_words = stopwords.words(\"english\")"
      ],
      "metadata": {
        "id": "w1BXfDd_OwnC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus = [ 'This is the first document.',\n",
        "     'This document is the second document.',\n",
        "     'And this is the third one.',\n",
        "     'Is this the first document?']"
      ],
      "metadata": {
        "id": "MQpSxAgtOeLd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vect = CountVectorizer() \n",
        "transformer = TfidfTransformer()"
      ],
      "metadata": {
        "id": "oHCEXiAhOs4U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = vect.fit_transform(corpus)"
      ],
      "metadata": {
        "id": "PwkETt5EO_Jq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sumDocu = np.zeros(X.shape[0]) \n",
        "docFreq = np.zeros(X.shape)"
      ],
      "metadata": {
        "id": "JuZK5HHZPTpv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(corpus)): \n",
        "  sumDocu[i] = sum(X.toarray()[i])\n",
        "  for j in range(len(X.toarray()[i])):\n",
        "     docFreq[i][j] = X.toarray()[i][j]/sumDocu[i]"
      ],
      "metadata": {
        "id": "_ut9I_GAPWR6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total = X.shape[0]\n",
        "numdoc = []\n",
        "for i in range(total):\n",
        "   count = [1 if x > 0 else 0 for x in X.toarray()[i]] \n",
        "   numdoc.append(count)"
      ],
      "metadata": {
        "id": "r5UCeKuMPciW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "numdoc = sum(np.array(numdoc))\n",
        "idf1 = np.array(total/numdoc)"
      ],
      "metadata": {
        "id": "ivpBuEcMPiXD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "idf = [np.log(x) for x in idf1] \n",
        "standard_tfidf = docFreq*idf"
      ],
      "metadata": {
        "id": "sPMjA7s-PlrY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('TF-IDF:')\n",
        "tfidf = transformer.fit_transform(X) \n",
        "print(vect.get_feature_names_out()) \n",
        "print()\n",
        "print(tfidf.toarray().T)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x2pbqIRaPp86",
        "outputId": "38257c26-5c59-4476-c622-94e771b8fb64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TF-IDF:\n",
            "['and' 'document' 'first' 'is' 'one' 'second' 'the' 'third' 'this']\n",
            "\n",
            "[[0.         0.         0.51184851 0.        ]\n",
            " [0.46979139 0.6876236  0.         0.46979139]\n",
            " [0.58028582 0.         0.         0.58028582]\n",
            " [0.38408524 0.28108867 0.26710379 0.38408524]\n",
            " [0.         0.         0.51184851 0.        ]\n",
            " [0.         0.53864762 0.         0.        ]\n",
            " [0.38408524 0.28108867 0.26710379 0.38408524]\n",
            " [0.         0.         0.51184851 0.        ]\n",
            " [0.38408524 0.28108867 0.26710379 0.38408524]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Problem #8"
      ],
      "metadata": {
        "id": "p11cHTADP_Iy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.set_printoptions(precision=4, suppress=True)\n",
        "from scipy import linalg as lg\n",
        "from sklearn.feature_extraction.text import CountVectorizer \n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "from scipy.linalg import svd"
      ],
      "metadata": {
        "id": "QBTERmdjQHB9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer = CountVectorizer()\n"
      ],
      "metadata": {
        "id": "3pwMgfs5QLfr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus1 = [\n",
        "'French revolution Napoleon',\n",
        "'French revolution Louis', 'French philosopher Voltaire', 'Catholic church',\n",
        "'Pope Catholic church',\n",
        "'Martin Luther Catholic church'\n",
        "]"
      ],
      "metadata": {
        "id": "pQJ9CizYQBBj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bag_of_words = vectorizer.fit_transform(corpus1) \n",
        "dtm = bag_of_words.todense()"
      ],
      "metadata": {
        "id": "mQoKw3LdUuHM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "svd = TruncatedSVD(n_components=2) \n",
        "TruncatedTDM = svd.fit_transform(np.asarray(dtm).T) \n",
        "TruncatedDTM = svd.fit_transform(np.asarray(dtm))"
      ],
      "metadata": {
        "id": "C-7Ohj8QU81J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.set_option('display.float_format', lambda x: '%.3f' % x) \n",
        "topic_encoded_df_Document = pd.DataFrame(TruncatedDTM, columns=[\"Topic-1\", \"Topic-2\"]) \n",
        "topic_encoded_df_Document [\"Corpus\"]= corpus1\n",
        "topic_encoded_df_Document.head()\n",
        "display(topic_encoded_df_Document[ ['Corpus','Topic-1','Topic-2'] ])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "id": "DtGVSpzGVX9w",
        "outputId": "91e1349c-c54d-48ba-d616-15651e14e4ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                          Corpus  Topic-1  Topic-2\n",
              "0     French revolution Napoleon    0.000    1.503\n",
              "1        French revolution Louis   -0.000    1.503\n",
              "2    French philosopher Voltaire    0.000    1.101\n",
              "3                Catholic church    1.287   -0.000\n",
              "4           Pope Catholic church    1.498   -0.000\n",
              "5  Martin Luther Catholic church    1.791   -0.000"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-49b850ae-4c99-425f-9971-f3c1cd01d976\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Corpus</th>\n",
              "      <th>Topic-1</th>\n",
              "      <th>Topic-2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>French revolution Napoleon</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1.503</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>French revolution Louis</td>\n",
              "      <td>-0.000</td>\n",
              "      <td>1.503</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>French philosopher Voltaire</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1.101</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Catholic church</td>\n",
              "      <td>1.287</td>\n",
              "      <td>-0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Pope Catholic church</td>\n",
              "      <td>1.498</td>\n",
              "      <td>-0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Martin Luther Catholic church</td>\n",
              "      <td>1.791</td>\n",
              "      <td>-0.000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-49b850ae-4c99-425f-9971-f3c1cd01d976')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-49b850ae-4c99-425f-9971-f3c1cd01d976 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-49b850ae-4c99-425f-9971-f3c1cd01d976');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**LSA has divided the documeents in two topics: French Revolution and Catholic Church** "
      ],
      "metadata": {
        "id": "d6bMoScDf4Ce"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "v0 = TruncatedDTM[:,0]\n",
        "v1 = TruncatedDTM[:,1]\n",
        "import matplotlib.pyplot as plt\n",
        "fig, ax = plt.subplots()\n",
        "print()\n",
        "plt.xlim([-1, 2])\n",
        "plt.ylim([-1, 2])\n",
        "ax.scatter(list(np.abs(v0)),list(np.abs(v1)),color='red')\n",
        "ax.axhline(y=0, color='k')\n",
        "ax.axvline(x=0, color='k')\n",
        "plt.xlabel(\"Topic-1\")\n",
        "plt.ylabel(\"Topic-2\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        },
        "id": "nxP3EPU7Vn0O",
        "outputId": "75d8b88a-d1fd-468a-d841-40cdcfb21782"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAEKCAYAAAA4t9PUAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAAsTAAALEwEAmpwYAAAT6UlEQVR4nO3df6zldX3n8efLGX7sKFsRJorAMFKJ1qZbwFuFurGTVVMlG7CtrpipoNFMhVptd90Ey8a6JqSt2biNQcAJJWI7i7/a6rgdQ0QY6KYdZKD8JujAQpnJIAgbLKFSGN/7x/mOHK/33rn3fu4533OG5yM5Od/P5/s53+/7O99772u+3/M935OqQpKk5XpB3wVIkqabQSJJamKQSJKaGCSSpCYGiSSpiUEiSWrSW5AkOT7JdUnuTnJXko/MMSZJPpNkV5Lbk5zaR62SpPmt7nHdzwL/papuSXIEcHOSb1XV3UNj3gac1D1eD1zaPUuSJkRvRyRVtbeqbumm/xm4Bzh21rCzgC/UwA7gxUmOGXOpkqQF9HlE8hNJ1gOnADfOmnUs8NBQe3fXt3fW6zcBmwBe+MIXvvbVr371yGrV6Nx7770AvOpVr+q5Eun55+abb/5BVa1dzmt7D5IkLwL+Cvj9qvrhcpZRVZuBzQAzMzO1c+fOFaxQ47JhwwYAtm/f3msd0vNRkgeX+9per9pKcgiDENlSVX89x5A9wPFD7eO6PknShOjzqq0Afw7cU1WfnmfYVuCc7uqt04AnqmrvPGMlST3o89TWG4D3AHckubXr+0NgHUBVXQZsA84AdgFPAe8bf5mSpIX0FiRV9X+AHGBMAb87nookScvhJ9slSU0MEklSE4NEktTEIJEkNTFIJElNDBJJUhODRJLUxCCRJDUxSCRJTQwSSVITg0SS1MQgkSQ1MUgkSU0MEklSE4NEktTEIJEkNTFIJElNDBJJUhODRJLUxCCRJDUxSCRJTQwSSVITg0SS1MQgkSQ1MUgkSU0MEklSE4NEktSk1yBJckWSR5LcOc/8DUmeSHJr9/j4uGvUmJx/Plx//eCxevWgLWkqrO55/Z8HLga+sMCYv6uq/ziectSL88+HSy99rr1v33PtSy7ppyZJi9brEUlV3QA83mcNmgCbNy+tX9JEmYb3SE5PcluSbyb5xb6L0Qjs27e0fkkTpe9TWwdyC3BCVT2Z5Azga8BJswcl2QRsAli3bt1YC9QKWLVq7tBYtWr8tUhasok+IqmqH1bVk930NuCQJEfPMW5zVc1U1czatWvHXqcabdq0tH5JE2WigyTJy5Kkm34dg3of67cqrbhLLoHzznuuvWrVoO0b7dJU6PXUVpKrgA3A0Ul2A38EHAJQVZcB7wDOS/Is8C/A2VVVPZWrUbrkErj77sH09u29liJpaXoNkqp69wHmX8zg8mBJ0oSa6FNbkqTJZ5BIkpoYJJKkJgaJJKmJQSJJamKQSJKaGCSSpCYGiSSpiUEiSWpikEiSmhgkkqQmBokkqYlBIklqYpBIkpoYJJKkJgaJJKmJQSJJamKQSJKaGCSSpCYGiSSpiUEiSWpikGgybNkCO3bA9dfD+vWDtqSpYJCof1u2wKZN8PTTg/aDDw7ahok0FQwS9e/CC+Gpp36676mnBv2SJp5Bov790z8trV/SRDFI1L9165bWL2miGCTq30UXwZo1P923Zs2gX9LEM0jUv40bYfNmOOywQfuEEwbtjRv7rUvSovQaJEmuSPJIkjvnmZ8kn0myK8ntSU4dd40ak40b4bTT4Nd+DR54wBCRpkjfRySfB966wPy3ASd1j03ApWOoSZK0BL0GSVXdADy+wJCzgC/UwA7gxUmOGU91kqTF6PuI5ECOBR4aau/u+n5Kkk1JdibZ+eijj46tOEnS5AfJolTV5qqaqaqZtWvX9l2OJD2vTHqQ7AGOH2of1/VJkibEpAfJVuCc7uqt04Anqmpv30VJkp6zus+VJ7kK2AAcnWQ38EfAIQBVdRmwDTgD2AU8Bbyvn0olSfPpNUiq6t0HmF/A746pHEnSMkz6qS1J0oQzSCRJTQwSSVITg0SS1MQgkSQ1MUgkSU0MEklSE4NEktTEIJEkNTFIJElNDBJJUhODRJLUxCCRJDUxSCRJTQwSSVKTeYMkyfFJvpjk75L8YZJDhuZ9bSzVSZIm3kJHJFcA24HfA44Brk9yVDfvhBHXJUmaEgt9Q+La7utuAX4vyW8DNyQ5E6jRlyZJmgYLBckhSQ6vqh8BVNVfJnkYuBp44ViqkyRNvIVObV0OvH64o6quAd4J3DnKoiRJ02PeI5Kq+p/z9P8j8JaRVSRJmipLuvw3yS2jKkSSNJ2W+jmSjKQKSdLUWmqQ/O1IqpAkTa0DBkmSVyQ5HKCq/luSf5Nk/cgrkyRNhcUckXwF+PFQe1/XJ0nSooJkdVX96/5GN33o6EqSJE2TxQTJo92n2QFIchbwg5VYeZK3Jrk3ya4kF8wx/71JHk1ya/f4wEqsV5K0chb6ZPt+HwS2JLmYwVVbDwHntK44ySrgsww+k7IbuCnJ1qq6e9bQL1XVh1rXJ0kajQMGSVXdB5yW5EVd+8kVWvfrgF1VdT9Aki8CZwGzg0SSNMHmDZIkv93dX+s/z+oHoKo+3bjuYxkc3ey3m1m3ZOn8VpI3At8F/qCqHpo9IMkmYBPAunXrGsuSJC3FQu+R7L8x4xHzPMbhG8D6qvp3wLeAK+caVFWbq2qmqmbWrl07ptIkSbDwvbY+1z3/9xGtew9w/FD7uK5vuIbHhpqXA58aUS2SpGVazAcST0zyje7qqUeSfD3JiSuw7puAk7oPPB4KnA1snbXuY4aaZwL3rMB6JUkraDGX//4v4MsMviXx5Qw+jHhV64qr6lngQwy+3+Qe4MtVdVeSTw5dbvzhJHcluQ34MPDe1vVKklbWYi7/XVNVfzHU/ssk/3UlVl5V24Bts/o+PjT9MeBjK7EuSdJoLCZIvtl9WPCLDL5i913AtiQvAaiqx0dYnyRpwi0mSP5T9/w7s/rPZhAsK/F+iSRpSi3mA4mvGEchkqTpdMAgSXIIcB7wxq5rO/C5qnpmhHVJkqbEYk5tXQocAlzStd/T9XkDRUnSgrdIWd1dovsrVfXLQ7Ou7S7HlSRpwc+RfKd73pfk5/d3dh9G3DfSqiRJU2OhU1vpnj8KXJfk/q69HnjfKIuSJE2PhYJk7dCdfz8HrOqm9wGnANeNsjBJ0nRYKEhWAS/iuSOT4deM6+6/kqQJt1CQ7K2qT46tEknSVFrozfbZRyKSJP2MhYLkTWOrQpI0teYNEm/GKElajMV8H4kkSfMySCRJTQwSSVITg0SS1MQgkSQ1MUgkSU0MEklSE4NEktTEIJEkNTFIJElNDBJJUhODRJLUxCCRJDXpNUiSvDXJvUl2JblgjvmHJflSN//GJOt7KFPSpNuyBdavhxe8YPC8Zct0LHuaaljAQt+QOFJJVgGfBd4C7AZuSrK1qu4eGvZ+4P9V1SuTnA38KfCu8VcraWJt2QKbNsFTTw3aDz44aANs3Di5y56mGg4gVdXPipPTgU9U1a937Y8BVNUfD425uhvzD0lWAw8Da2uBoo844oh67WtfO9riNRK33norACeffHKvdWjK7NgBTz/9s/2HHQannTa5y56wGq6//vqbq2pmOa/t89TWscBDQ+3dXd+cY6rqWeAJ4KjZC0qyKcnOJDufeeaZEZUraSLN9Ud2of5JWfY01XAAvZ3aWklVtRnYDDAzM1Pbt2/vtyAty4YNGwBw/2lJ1q8fnO6Z7YQToPVnaZTLnrAakiz7tX0ekewBjh9qH9f1zTmmO7X1c8BjY6lO0nS46CJYs+an+9asGfRP8rKnqYYD6DNIbgJOSvKKJIcCZwNbZ43ZCpzbTb8DuHah90ckPQ9t3AibNw/+h54MnjdvXpk3oke57Gmq4QB6e7MdIMkZwJ8Bq4ArquqiJJ8EdlbV1iSHA38BnAI8DpxdVfcvtMyZmZnauXPniCvXKHhqS+pPkmW/2d7reyRVtQ3YNqvv40PTPwLeOe66JEmL5yfbJUlNDBJJUhODRJLUxCCRJDUxSCRJTQwSSVITg0SS1MQgkSQ1MUgkSU0MEklSE4NEktTEIJEkNTFIJElNDBJJUhODRJLUxCCRJDUxSCRJTQwSSVITg0SS1MQgkSQ1MUgkSU0MEklSE4NEktTEIJEkNTFIJElNDBJJUhODRJLUpJcgSfKSJN9K8r3u+ch5xu1Lcmv32DruOiVJB9bXEckFwLer6iTg2117Lv9SVSd3jzPHV54kabH6CpKzgCu76SuBt/dUhySpUV9B8tKq2ttNPwy8dJ5xhyfZmWRHkrePpzRJ0lKsHtWCk1wDvGyOWRcON6qqktQ8izmhqvYkORG4NskdVXXfHOvaBGwCWLduXWPlkqSlGFmQVNWb55uX5PtJjqmqvUmOAR6ZZxl7uuf7k2wHTgF+JkiqajOwGWBmZma+UJIkjUBfp7a2Aud20+cCX589IMmRSQ7rpo8G3gDcPbYKJUmL0leQ/AnwliTfA97ctUkyk+TybswvADuT3AZcB/xJVRkkkjRhRnZqayFV9Rjwpjn6dwIf6Kb/HvilMZcmSVoiP9kuSWpikEiSmhgkkqQmBokkqYlBIklqYpBIkpoYJJKkJgaJJKmJQSJJamKQSJKaGCSSpCYGiSSpiUEiSWpikEiSmhgkkqQmBokkqYlBIklqYpBIkpoYJJKkJgaJJKmJQSJJamKQSJKaGCSSpCYGiSSpiUEiSWpikEiSmhgkkqQmBokkqUkvQZLknUnuSvLjJDMLjHtrknuT7EpywThrlCQtTl9HJHcCvwncMN+AJKuAzwJvA14DvDvJa8ZTniRpsVb3sdKqugcgyULDXgfsqqr7u7FfBM4C7h55gZKkReslSBbpWOChofZu4PVzDUyyCdjUNZ9OcueIa+vT0cAP+i5ihI5OclBvHwf5/uPg3b6DedsAXrXcF44sSJJcA7xsjlkXVtXXV3JdVbUZ2Nytd2dVzfu+y7Rz+6ab2ze9DuZtg8H2Lfe1IwuSqnpz4yL2AMcPtY/r+iRJE2SSL/+9CTgpySuSHAqcDWztuSZJ0ix9Xf77G0l2A6cDf5vk6q7/5Um2AVTVs8CHgKuBe4AvV9Vdi1j85hGVPSncvunm9k2vg3nboGH7UlUrWYgk6Xlmkk9tSZKmgEEiSWoy9UFysN9uJclLknwryfe65yPnGbcvya3dY+IvSjjQ/khyWJIvdfNvTLK+hzKXbRHb994kjw7tsw/0UedyJLkiySPzfV4rA5/ptv32JKeOu8YWi9i+DUmeGNp3Hx93jcuV5Pgk1yW5u/u7+ZE5xix9/1XVVD+AX2DwQZrtwMw8Y1YB9wEnAocCtwGv6bv2RW7fp4ALuukLgD+dZ9yTfde6hG064P4Azgcu66bPBr7Ud90rvH3vBS7uu9Zlbt8bgVOBO+eZfwbwTSDAacCNfde8wtu3Afjffde5zG07Bji1mz4C+O4cP5tL3n9Tf0RSVfdU1b0HGPaT261U1b8C+2+3Mg3OAq7spq8E3t5fKStmMftjeLu/CrwpB7inzgSZ5p+3A6qqG4DHFxhyFvCFGtgBvDjJMeOprt0itm9qVdXeqrqlm/5nBlfEHjtr2JL339QHySLNdbuV2f94k+qlVbW3m34YeOk84w5PsjPJjiRvH09py7aY/fGTMTW4FPwJ4KixVNdusT9vv9WdOvhqkuPnmD+tpvn3bbFOT3Jbkm8m+cW+i1mO7nTxKcCNs2Ytef9N8r22fmKct1vpw0LbN9yoqkoy3/XaJ1TVniQnAtcmuaOq7lvpWrVivgFcVVVPJ/kdBkdf/6HnmrQ4tzD4fXsyyRnA14CT+i1paZK8CPgr4Per6oety5uKIKmD/HYrC21fku8nOaaq9naHl4/Ms4w93fP9SbYz+J/GpAbJYvbH/jG7k6wGfg54bDzlNTvg9lXV8LZczuC9sIPFRP++tRr+w1tV25JckuToqpqKGzomOYRBiGypqr+eY8iS99/z5dTWNN9uZStwbjd9LvAzR2BJjkxyWDd9NPAGJvt2+4vZH8Pb/Q7g2ureCZwCB9y+Weecz2RwrvpgsRU4p7v65zTgiaHTs1Mvycv2v1+X5HUM/o5OxX9yurr/HLinqj49z7Cl77++ryJYgasQfoPBObynge8DV3f9Lwe2zboS4bsM/pd+Yd91L2H7jgK+DXwPuAZ4Sdc/A1zeTf8qcAeDq4PuAN7fd92L2K6f2R/AJ4Ezu+nDga8Au4DvACf2XfMKb98fA3d1++w64NV917yEbbsK2As80/3uvR/4IPDBbn4YfCndfd3P45xXU07qYxHb96GhfbcD+NW+a17Ctv17oIDbgVu7xxmt+89bpEiSmjxfTm1JkkbEIJEkNTFIJElNDBJJUhODRJLUxCCRFiHJUUN3e304yZ6h9qGLXMYHk5yzhHW+McktSZ5N8o7lVy+Nlpf/SkuU5BMM7rb8P0a8nvXAvwU+Cmytqq+Ocn3ScnlEIi1Tkjcl+cckd3TfYbH/7gIPJPlU1/+dJK/s+j+R5KPd9CuTXNPd+O+WJD8/e/lV9UBV3Q78eKwbJi2RQSItz+HA54F3VdUvMbhv3XlD85/o+i8G/myO128BPltVv8zgzgQHzS1E9PxjkEjLswr4v1X13a59JYMvRNrvqqHn04dfmOQI4Niq+huAqvpRVT014nqlkTFIpNGoeabnleSi/W/gj6YkaTQMEml59gHr97//AbwHuH5o/ruGnv9h+IU1+Ga63fu/gCyD76dfU1UXVtXJVXXySCuXVphBIi3Pj4D3AV9JcgeDN8QvG5p/ZJLbgY8AfzDH698DfLgb8/fM8cVmSX4lyW7gncDnkty1wtsgrQgv/5VWWJIHGNx6eyq+6Ehq5RGJJKmJRySSpCYekUiSmhgkkqQmBokkqYlBIklqYpBIkpr8f91TRdvBD9vVAAAAAElFTkSuQmCC\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "TruncatedDTM = TruncatedDTM/np.linalg.norm(TruncatedDTM, axis=1).reshape(-1, 1)\n",
        "cosine_similarity =  abs(np.dot(np.array(TruncatedDTM), np.array(TruncatedDTM.T)))\n",
        "print(\"Cosine Similarity\\n\",cosine_similarity)\n",
        "print()\n",
        "print(\"Cosine Distance\\n\",1-cosine_similarity)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_0zbk-UcVvmq",
        "outputId": "f0a3743e-aaab-4575-f26d-f07bec7c738b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cosine Similarity\n",
            " [[1. 1. 1. 0. 0. 0.]\n",
            " [1. 1. 1. 0. 0. 0.]\n",
            " [1. 1. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 1. 1.]\n",
            " [0. 0. 0. 1. 1. 1.]\n",
            " [0. 0. 0. 1. 1. 1.]]\n",
            "\n",
            "Cosine Distance\n",
            " [[0. 0. 0. 1. 1. 1.]\n",
            " [0. 0. 0. 1. 1. 1.]\n",
            " [0. 0. 0. 1. 1. 1.]\n",
            " [1. 1. 1. 0. 0. 0.]\n",
            " [1. 1. 1. 0. 0. 0.]\n",
            " [1. 1. 1. 0. 0. 0.]]\n"
          ]
        }
      ]
    }
  ]
}